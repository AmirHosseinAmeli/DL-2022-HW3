\begin{enumerate}[label=(\alph*)]
	
	\item
	
	به طور کلی نمی توان هیچ مدلی را برتر دانست، و بسته به کاربرد هر کدام می توانند مفید واقع شوند. هر دو مدل نقاط ضعف و قوت خود می باشند. هر یک دارای معماری خاص خود بوده بسته به اینکه کدام مدل از زیر مجموعه GAN یا VAE مورد استفاده قرار گیرد، کیفیت خروجی تغییرات بسیاری خواهد کرد. به عنوان مثال، هنگامی که از DCGAN استفاده کنیم، سیستم یادگیری به صورت غیر نظارتی خواهد بود، در حالی که در VAE هر دو ساختار نیمه-نظارتی و نظارت شده استفاده شده است. همچنین، اندازه گیری خطای DCGAN مشکل می باشد چرا که از مکانیزم minimax برای یادگیری استفاده کرده و خطای MSE آن در هر Epoch تغییرات محسوسی را دارد. در نتیجه، بسته به کاربرد و تعداد داده های موجود برای آموزش، عملکرد هر یک از مدل ها می تواند به دیگری برتری داشته باشد.
	
	\item
	
	تابع relu همانطور که اشاره شد، یکی از پرکاربردترین توابع در زمینه توابع فعالسازی می باشد. اما مشکلی که در هنگام استفاده از این تابع در برخی موارد در شبکه های حساسی همانند generator می تواند ایجاد شود، عدم آموزش دیدن شبکه از جایی به بعد می باشد. علت این امر آن است که در تابع relu ، هنگامی که ورودی کوچکتر یا مساوی صفر باشد، خروجی صفر خواهد شد، و این بدان معناست که در شبکه هایی همانند generator در شبکه های GAN که آموزش به شدت حساسی دارند و گاهی آموزش شبکه بسیار کند پیش می رود، یعنی rate آموزش حوالی صفر است، با استفاده از relu عملا آموزش متوقف شده و شبکه خروجی مطلوب را تولید نخواهد کرد. از آن جایی که توابعی همانند leaky relu در حوالی صفر و مقادیر کوچکتر از آن، مقداری غیر از صفر دارند لذا شبکه با استفاده از آن ها حتی در زمان هایی که rate آموزش پایین است نیز شانس ادامه آموزش دیدن را دارد.
	
\end{enumerate}